{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e5a9f078-ff13-4540-970e-9f15b4244209",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61746d8f-6bbb-4d3b-9ca2-94c497c71864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Academic</th>\n",
       "      <th>Facilities</th>\n",
       "      <th>Career</th>\n",
       "      <th>Financial</th>\n",
       "      <th>Diversity</th>\n",
       "      <th>Wellness</th>\n",
       "      <th>Social</th>\n",
       "      <th>Technology</th>\n",
       "      <th>Sustainability</th>\n",
       "      <th>Policy</th>\n",
       "      <th>Communication</th>\n",
       "      <th>Ethics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Create innovation hubs that support entre...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Create safe social spaces for students to...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Develop leadership programs focused on pu...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Develop mentorship programs that connect ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Encourage interdisciplinary collaboration...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  Academic  Facilities  \\\n",
       "0      \"Create innovation hubs that support entre...         0           0   \n",
       "1      \"Create safe social spaces for students to...         0           0   \n",
       "2      \"Develop leadership programs focused on pu...         0           0   \n",
       "3      \"Develop mentorship programs that connect ...         0           0   \n",
       "4      \"Encourage interdisciplinary collaboration...         0           0   \n",
       "\n",
       "   Career  Financial  Diversity  Wellness  Social  Technology  Sustainability  \\\n",
       "0       1          0          0         0       0           0               0   \n",
       "1       0          0          0         0       1           0               0   \n",
       "2       1          0          0         0       0           0               0   \n",
       "3       1          0          0         0       0           0               0   \n",
       "4       0          0          0         0       1           0               0   \n",
       "\n",
       "   Policy  Communication  Ethics  \n",
       "0       0              0       0  \n",
       "1       0              0       0  \n",
       "2       0              0       0  \n",
       "3       0              0       0  \n",
       "4       0              0       0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This is a dataset of fake student survey responses generated with ChatGPT\n",
    "surveys = pd.read_excel(\"fake_student_survey_data.xlsx\")\n",
    "text = surveys['text']\n",
    "surveys.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cfa44784-c238-4be3-8361-99f75c515844",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kevin\\AppData\\Local\\Temp\\ipykernel_39580\\3143108953.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  career_df.rename(columns={'Career': 'label'}, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'text': '    \"Create innovation hubs that support entrepreneurial ventures. Pursuing my business ideas was challenging without dedicated resources and mentorship.\"',\n",
       " 'label': 1}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Converting dataframe to Huggingface Dataset\n",
    "#We're going to focus on the career label for binary classification\n",
    "career_df = surveys[['text', 'Career']]\n",
    "career_df.rename(columns={'Career': 'label'}, inplace=True)\n",
    "\n",
    "from datasets import Dataset\n",
    "train_career = Dataset.from_pandas(career_df)\n",
    "train_career[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cdee4d6a-0f03-4c8f-afd8-7d98618250ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Career</th>\n",
       "      <th>Social</th>\n",
       "      <th>Diversity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Offer workshops that teach specific skills rel...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Increase partnerships with companies to provid...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Provide personalized career counseling session...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Integrate courses that prepare students for in...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Create mentorship programs where students can ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  Career  Social  \\\n",
       "0  Offer workshops that teach specific skills rel...       1       0   \n",
       "1  Increase partnerships with companies to provid...       1       0   \n",
       "2  Provide personalized career counseling session...       1       0   \n",
       "3  Integrate courses that prepare students for in...       1       0   \n",
       "4  Create mentorship programs where students can ...       1       0   \n",
       "\n",
       "   Diversity  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Here is a eval dataset of fake student survey responses generated with Chat GPT to test a few binary classification models\n",
    "surveys_eval = pd.read_excel(\"fake_survey_eval_data.xlsx\")\n",
    "eval_text = surveys_eval['text']\n",
    "surveys_eval.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7c94fbf6-ca7b-4507-8fea-2ee048b9dd77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kevin\\AppData\\Local\\Temp\\ipykernel_39580\\595259346.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  career_eval.rename(columns={'Career': 'label'}, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'text': 'Offer workshops that teach specific skills relevant to different industries, such as project management, data analysis, or digital marketing.',\n",
       " 'label': 1}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "career_eval = surveys_eval[['text', 'Career']]\n",
    "career_eval.rename(columns={'Career': 'label'}, inplace=True)\n",
    "\n",
    "eval_career = Dataset.from_pandas(career_eval)\n",
    "eval_career[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "0524c7f6-b9df-411b-91dd-6933d380a0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose model\n",
    "#model_path = \"roberta-base\"\n",
    "model_path = \"microsoft/deberta-v3-base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "b6a12882-750d-4b5d-bab7-e2ccb573266b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ecff76c3bd1411f87d1ab415b0025a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kevin\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\kevin\\.cache\\huggingface\\hub\\models--microsoft--deberta-v3-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28ccf7ae2e75404f910fe542c54185d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/579 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bdfb4e183c24686b2ba74a98457e8f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kevin\\anaconda3\\Lib\\site-packages\\transformers\\convert_slow_tokenizer.py:562: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "fd06ebaa-fd5c-4db4-9d63-48c050a9feb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(surveys):\n",
    "    return tokenizer(surveys['text'], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "051599eb-3751-422e-9b6d-f7ec73981eeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d4316bddef149468dfe7d4aab14f211",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/90 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "tokenized_surveys = train_career.map(preprocess_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "ab0a44ce-cfc9-4353-bbcb-9c0d35dbf7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here is what our data looks like after tokenization\n",
    "#tokenized_surveys[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "265ac2cf-2078-4829-9b40-4d09a27de82b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28cdfec306e54e709a87504b2baef6a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/60 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_eval = eval_career.map(preprocess_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "74217c5a-065c-4dfd-9493-3cd4dfdec2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "dfe389a0-035c-41de-8861-32db0f88eaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "e803bb3f-7a7c-4559-8329-39fc4844fa9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "ccf1d57f-348c-49e6-80bd-a640f2cfe898",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {0: \"Not Career Related\", 1: \"Career Related\"}\n",
    "label2id = {\"Not Career Related\": 0, \"Career Related\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "e6cd3961-3383-4220-b176-7c4488741323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46842b2fe40c42a0b8d54ea9ca7c802c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:  92%|#########1| 341M/371M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#Import the necessary packages \n",
    "#We're going to test both RoBERTa and DeBERTa for binary classification\n",
    "#You can change the model by updating the model_path variable above\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_path\n",
    "    ,num_labels=2 \n",
    "    ,id2label=id2label\n",
    "    ,label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "193608cb-7515-4dc8-ac33-6e3419731295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='184' max='184' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [184/184 21:23, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.649381</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.733775</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.629783</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.603087</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.581126</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.677386</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.758316</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.801666</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=184, training_loss=0.27229918604311737, metrics={'train_runtime': 1290.8982, 'train_samples_per_second': 0.558, 'train_steps_per_second': 0.143, 'total_flos': 11777514272328.0, 'train_loss': 0.27229918604311737, 'epoch': 8.0})"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"deberta_survey_example\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=8,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=False,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_surveys,\n",
    "    eval_dataset=tokenized_eval,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "c0d173ed-5be4-4dfe-87f8-c6ab46b8e998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'Not Career Related', 'score': 0.6981530785560608}]\n",
      "[{'label': 'Not Career Related', 'score': 0.923100471496582}]\n"
     ]
    }
   ],
   "source": [
    "#Test out some predictions -- on a very obvious career example\n",
    "from transformers import pipeline\n",
    "clf = pipeline(\"text-classification\", model=model, tokenizer=tokenizer)\n",
    "answer = clf(\"We should focus on learning skills for our career.\")\n",
    "answer2 = clf(\"There should be more snacks available between classes\")\n",
    "print(answer)\n",
    "print(answer2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "ea13f582-9b2b-4c7c-afee-7c4089fc1991",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#Since this dataset is unbalanced (only mentions career stuff about 10% of the time), let's add class weights \n",
    "#to assign higher importance to the minority class\n",
    "\n",
    "#Resetting the model\n",
    "weighted_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_path, num_labels=2, id2label=id2label, label2id=label2id\n",
    ")\n",
    "\n",
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get('logits')\n",
    "        # Here we update the loss function \n",
    "        loss_fct = nn.CrossEntropyLoss(weight=torch.tensor([0.1, 0.9])) #Set class weights here\n",
    "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "weighted_trainer = CustomTrainer(\n",
    "    model=weighted_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_surveys,\n",
    "    eval_dataset=tokenized_eval,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "a24c907a-c387-415b-a60f-87d5d8ab5947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='184' max='184' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [184/184 14:58, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.726213</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.696942</td>\n",
       "      <td>0.366667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.646362</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.846927</td>\n",
       "      <td>0.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.745866</td>\n",
       "      <td>0.816667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.844164</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.834919</td>\n",
       "      <td>0.816667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.836908</td>\n",
       "      <td>0.816667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=184, training_loss=0.31678048424098804, metrics={'train_runtime': 902.719, 'train_samples_per_second': 0.798, 'train_steps_per_second': 0.204, 'total_flos': 11777514272328.0, 'train_loss': 0.31678048424098804, 'epoch': 8.0})"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "2e4a81d6-3ee3-4e33-96b5-5ec21ad19875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'Career Related', 'score': 0.6545425653457642}]\n",
      "[{'label': 'Not Career Related', 'score': 0.5999439358711243}]\n"
     ]
    }
   ],
   "source": [
    "#Test out some predictions -- on a very obvious career example\n",
    "from transformers import pipeline\n",
    "weighted_clf = pipeline(\"text-classification\", model=weighted_model, tokenizer=tokenizer)\n",
    "weighted_answer = weighted_clf(\"We should focus on learning skills for our career.\")\n",
    "weighted_answer2 = weighted_clf(\"There should be more snacks available between classes\")\n",
    "print(weighted_answer)\n",
    "print(weighted_answer2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0fa439-98bc-4054-8568-f49d29b4251c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
